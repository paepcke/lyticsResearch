<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" type="text/css" href="umichWhatWeDo.css"/>
  </head>  

  <body>

    <h1>Stanford Lytics Lab Research Summary 2013-2015</h1> 

    <div class="columns">
    The Stanford Lytics Lab comprises a collection of faculty and
    students from a number of Schools and Departments. Most notably,
    students from the School of Education and the Department of
    Computer Science have been collaborating to research how learning
    occurs on Stanford's online courses. Below we summarize major
    results up to May 2015.
    </div>

    <h2>Research Results</h2>

    The following expandable table partitions our work into four
    groups. The first three cite published research papers. The last
    group lists currently ongoing efforts.

    <!-- <ul class="accordion" id="vertical">  -->
    <ul class="accordion">  
      <li class="exploringMotivation">
	<div>
	  <h3>Exploring motivation</h3>
	  <p/>
	    <!-- See .css file for explanation why we use the liNormal
		 class instead of <li> tags: -->
	    <div class="liNormal">We showed that displaying <a
	    class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2460296.2460317">instructor
	    faces</a> in instructional videos at strategic moments
	    improves learner enjoyment via the perception of social
	    presence. On the other hand, cognitive load increases. No
	    difference was found in attrition or learning outcomes
	    between the display of faces, and not showing faces at
	    all. An <a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2556288.2557207">
	    additional study</a> used eye tracking to gain detailed
	    understanding of learner behavior in the presence or
	    absence of instructor faces.</div>
	    
	    <div class="liNormal">We examined how an understanding of
	    <a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2699735">learner
	    motivations</a> when entering a course provides insight
	    into the subsequent needs of those learners. Example
	    recommendations from these correlations are for the
	    creation of social spaces outside particular courses, and
	    content modularization.</div>
	    
	    <div class="liNormal">A large study of 67,000 learners in
	    20 courses showed a geographical and gender <a
	    class="aDarkBackground"
	    href="http://rene.kizilcec.com/wp-content/uploads/2013/02/kizilcec2015attrition.pdf">
	    achievement gap</a> in both performance and
	    persistence. Resulting insights into why learners leave
	    online courses informs models of targeted
	    interventions.</div>
	    
	    <div class="liNormal">Assessment can be <a class="aDarkBackground"
	    href="http://www.rpajournal.com/dev/wp-content/uploads/2014/10/A1.pdf">
	    significantly improved</a> through the use of detailed
	    learner interaction data collection. Continuous data
	    analysis can, among other examples, enable targeted
	    feedback.</div>
	  
	</div>
      </li>
      <li class="groupsOnline">
	<div>
	  <h3>Groups online</h3>
	  <p/>
	    <div class="liNormal">We examined how <a
	    class="aLightBackground"
	    href="http://doi.acm.org/10.1145/2556325.2566249">superposters</a>
	    on course forum facilities impact forum quality. Results
	    show that such frequent posters do enhance forum quality,
	    and do not suppress less prolific contributors.</div>

	    <div class="liNormal">An attempt to <a
	    class="aLightBackground"
	    href="http://rene.kizilcec.com/wp-content/uploads/2013/02/kizilcec2014encouraging2014elearning.pdf">
	    encourage forum contributions</a> by appealing
	    alternatively to self interest, and the benefit for other
	    learners proved ineffective.</div>

	    <div class="liNormal">The report on an experiment that <a
	    class="aLightBackground"
	    href="http://people.csail.mit.edu/zp/moocshop2013/paper_6.pdf">
	    created learner groups</a> in online courses includes a
	    review of relevant literature, and suggestions for
	    research directions.</div>

	    <div class="liNormal">Experimentation with over 63,000 <a
	    class="aLightBackground"
	    href="http://web.stanford.edu/~cpiech/bio/papers/tuningPeerGrading.pdf">
	    peer grades</a> provided insights in how to improve peer
	    grading results, and assign graders to gradees. Grading
	    behavior was related to learner aspects such as engagement
	    and performance.</div>

	    <div class="liNormal">An <a class="aLightBackground"
	    href="http://link.springer.com/article/10.1007%2Fs11412-013-9181-4#page-1">
	    eye tracker</a> allowed remotely collaborating learners to
	    see where their study partner was looking on their
	    screen. Measurements showed that learners with this
	    information achieved a higher quality of collaboration,
	    and learning gain when compared with a control group. A
	    second study explored how <a class="aLightBackground"
	    href="http://doi.acm.org/10.1145/2460296.2460317"> network
	    analysis</a> can be applied to the resulting gaze
	    patterns.</div>
	</div>
      </li>

      <li class="educationalGadgets">
	<div>
	  <h3>Educational gadgets</h3>
	  <p/>
	    <div class="liNormal">The development and deployment of a
	    middle school Computer Science curriculum showed how <a
	    class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2556325.2567883">instructor
	    dashboards</a> can be used to promote student
	    learning.</div>
	    
	    <div class="liNormal"><a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2566486.2568023">Codewebs</a>
	    is a search engine over online learner coding homework
	    submissions. Associated indexing enables retrieval of
	    common mistakes, and consequent directed feedback.</div>
	    
	    <div class="liNormal">A study of <a
	    class="aDarkBackground"
	    href="http://people.csail.mit.edu/zp/moocshop2013/paper_16.pdf">syntax
	    and functionality differences</a> among a million
	    programming assignment submissions shows that a small
	    number of learner approaches can be identified. This
	    sparsity enables widely relevant instructor feedback
	    across those differences.</div>

	    <div class="liNormal">An <a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2559206.2581351">online
	    prompting</a> facility asks learners to explain their
	    beliefs. An associated study explains the conditions under
	    which this procedure is successful in clearing up learner
	    misconceptions.</div>
	    
	    <div class="liNormal">A <a class="aDarkBackground"
	    href="http://lytics.stanford.edu/wordpress/wp-content/uploads/2013/07/Last-Version.pdf">
	    dropout predictor</a> succeeds in red-flagging 40%-50% of
	    dropouts while they are still active. An additional
	    40%-45% are red-flagged within 14 days of absence from the
	    course.</div>

	    <div class="liNormal">A procedure that <a
	    class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2556325.2567850">
	    compensates for non-response bias</a> in online course
	    surveys was developed, in addition to quantifying the
	    effect of such bias. A <a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2556325.2567852">survey
	    response item</a> that elicits reasons for enrollment was
	    developed as well.</div>

	    <div class="liNormal">The <a class="aDarkBackground"
	    href="http://doi.acm.org/10.1145/2675133.2675166">Talkabout</a>
	    facility enables large online classes to create
	    small, video connected discussion
	    groups. Experiences with the system show that high
	    geographic diversity is beneficial to learning
	    outcomes.</div>

	    <div class="liNormal">We created <a
	    class="aDarkBackground"
	    href="http://ilpubs.stanford.edu:8090/1127/">classifiers</a>
	    that identify forum post properties, such as learner
	    confusion. Using text in confused posts we query closed
	    caption files of relevant instructional videos. The
	    results point learners to promising snippets within those
	    otherwise difficult to access resources.
	    </div>

	</div>
      </li>
      
      <li class="ongoing">
	<div>

	  <h3>Ongoing</h3>

	  <p/>
	    <div class="liNormal">An interactive learning tool for teaching theorem proofing.</div>
	    <div class="liNormal">Interactive physical simulators</div>
	    <div class="liNormal">Robotic simulation for teaching choreography online</div>
	    <div class="liNormal">Collective document annotations</div>
	</div>
      </li>
    </ul> <!-- accordion -->
    
    <h2>Resources</h2>

    <!-- Don't know why the following text does not show
         up as columns! -->
    <div class="colums">
      Stanford's courses are delivered through three
      platforms. Lagunita, a local instance of OpenEdX, Coursera, and
      NovoEd. Data for our research originates from all three
      platforms. Beyond grades we collect interaction logs at the
      granularity of video player operations, assignment submissions,
      forum activity, and survey results. Details are found on our <a
      href="http://datastage.stanford.edu"> Datastage</a> site.
      <p/>
      Also at that site is a 30,000 post forum data set. Each post was
      hand-classified by three individuals. These raters judged
      whether a given post was a question, answer, or opinion, and to
      which extent the posts expressed confusion, and sentiment
      valence. Raters also evaluated the urgency for an instructor to
      examine the post. This dataset is available for researchers.
      <p/>
      Stanford faculty is a tremendous resource in that we have been
      able to install A/B tests in a number of their courses. Many of
      the studies listed earlier relied on this willingness to explore
      teaching alternatives.
      <p/>
      With considerable effort we have created a data collection
      infrastructure that converts the often inscrutible platform
      exports into formats that social scientists understand, and that
      are amenable to the many existing statistics tools. The data are
      therefore available to Stanford researchers. In addition, we are
      able to share Lagunita data collected after June 14, 2014 with
      researchers at other institutions.
    </div>
  </body>
</html>
